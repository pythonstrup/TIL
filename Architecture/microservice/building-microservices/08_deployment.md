# Chapter 08 배포

- 단일 프로세스로 된 모놀리식 애플리케이션의 배포는 매우 간단한 과정.
- 하지만 상호 의존성과 풍부한 기술 선택지를 갖춘 마이크로서비스는 완전히 별개.

## 1. 논리적에서 물리적으로

- 마이크로서비스를 바라보는 논리적 관점은 현실의 인프라스트럭처에 마이크로서비스를 실제로 실행할 때 수반되는 많은 복잡성을 숨겨준다.

### 1-1. 다수 인스턴스

- 두 마이크로서비스의 배포 토폴로지를 생각해보면 하나가 다른 하나와 대화하는 것만큼 간단하지 않다.
  - 우선 각 서비스의 인스턴스가 1개 이상 있을 가능성이 높다.
  - 서비스의 다수 인스턴스를 사용하면 더 많은 부하를 처리할 수 있고 단일 인스턴스 고장을 감내할 수 있으므로 시스템의 견고성이 향상될 수 있다.
  - 따라서 잠재적으로는 하나 이상의 인스턴스가 하나 이상의 인스턴스와 통신하게 된다.
  - 인스턴스 간 통신을 처리하는 방법은 통신 메커니즘의 특성에 좌우되지만, HTTP 기반의 API 형식을 사용한다고 가정하면 로드 밸런서만으로도 다른 인스턴스에 대한 요청 라우팅을 처리하기에 충분하다.
- 견고성을 이유로 서비스의 여러 인스턴스를 둔다면, 그 인스턴스가 모두 동일한 기본 하드웨어에 있는지 확인하고 싶을 것이다.
  - 다른 여러 데이터 센터에 여러 인스턴스를 분산해야 할 수도 있다.
  - 이것은 적어도 주요 클라우드 공급자와 작업할 때는 절대적인 고려 사항이다.
  - 관리형 머신 등과 관련해서 AWS, 애저, 구글 클라우드 모두 단일 머신에 대한 SLA를 제공하지 않으며 단일 `가용 영역 avilability zone`(이러한 공급자의 데이터 센터와 거의 같은 개념)에 대한 SLA도 제공하지 않는다.
  - 실제로 이 말은 배포하는 모든 솔루션이 여러 가용 영역에 분산돼야 한다는 것을 의미한다.

### 1-2. 데이터베이스

- 마이크로서비스의 내부 상태 관리는 감춰져야 하므로 상태 관리를 위해 사용되는 데이터베이스도 모두 마이크로서비스 내부에 숨겨져 있는 것으로 간주된다.
- 여러 인스턴스가 있다고 가정.
  - 마이크로서비스 인스턴스마다 자신만의 데이터베이스가 있어야 할까? => 그렇지 않다.
  - 논리적으로 동일한 서비스의 서로 다른 인스턴스 간에는 어느 정도의 공유 상태가 필요하다.
  - 상태에 액세스하고 조작하는 로직은 논리적으로 하나의 마이크로서비스에 여전히 유지된다.

#### 데이터 배포 및 확장

- 하지만 하나의 데이터베이스를 모든 인스턴스가 사용하는 것은 하부 데이터베이스의 중복성이나 확장성 요구에 대한 관심을 무시하는 것이다.
  - 대체로 데이터베이스 배포는 다양한 이유로 여러 머신에서 호스팅되며, 일반적인 예는 `기본 primary` 노드와 읽기 전용으로 지정된 하나 이상의 노드(이러한 노드를 일반적으로 `읽기 복제본 read replica`이라고 한다.) 간에 읽기 및 쓰기에 대한 부하를 분할하는 것이다.
  - 여러 개의 읽기 복제본과 하나의 쓰기 데이터베이스
  - 모든 읽기 전용 트래픽은 읽기 복제본 노드 중 하나로 들어가며, 읽기 노드를 추가하면 읽기 트래픽을 더 확장할 수 있다.
  - 관계형 데이터베이스가 작동하는 방식 때문에 머신을 추가해 쓰기 트래픽을 확장하기는 더 어려우므로(일반적으로 `샤딩 모델 sharding model`이 필요해 복잡성이 추가된다.) 더 확장하려면, 흔히 읽기 전용 트래픽을 읽기 복제본에 옮겨서 쓰기 노드에 더 많은 용량을 확보하곤 한다.
- 온프레미스 vs 클라우드
  - `온프레미스 on-premise` 방식으로 실행하는 조직은 비용상의 이유로 여러 데이터베이스를 공유 데이터베이스 인프라에서 호스팅할 가능성이 훨씬 더 높다. 하드웨어를 프로비저닝하고 관리하는 것은 괴로운 일이므로(적어도 지금까지 가상화된 인프라스트럭처에서 데이터베이스를 실행하지 않는 경향이 있다.) 그다지 원치 않게 된다.
  - 반면 공용 클라우드 공급자를 기반으로 운영하는 팀은 마이크로서비스별로 전용 데이터베이스 인프라스트럭처를 프로비저닝할 가능성이 훨씬 높다. 이 인프라스트럭처를 프로비저닝하고 관리하는 비용은 훨씬 저렴하다. 또한 각 마이크로서비스 소유자는 공유 서비스에 의존하지 않고 더 많은 제어를 할 수 있다.

### 1-3. 환경

- 소프트웨어를 배포하면, 그 소프트웨어는 환경에서 실행된다.
  - 각 환경은 일반적으로 서로 다른 용도로 사용되며, 보유할 수 있는 정확한 환경 수는 소프트웨어를 개발하는 방법과 최종 사용자에게 소프트웨어를 배포하는 방법에 따라 크게 달라질 수 있다.
- 일반적으로는 소프트웨어가 여러 가지 `사전 운영 preproduction` 환경을 통해 이동하는 것으로 생각하며, 각 환경은 소프트웨어를 개발하고 운영 준비 상태를 테스트할 수 있도록 특정 목적을 수행한다.
- 마이크로서비스는 최종적으로 사용자가 새 소프트웨어를 사용할 운영 환경에 도달하기 전에 여러 환경을 거치게 된다.
  1. 개발자의 로컬 노트북
  2. CI 환경
  3. 사전 운영 환경
  4. 운영 환경
- 모든 환경이 운영 환경의 정확한 복사본이 된다면 가장 이상적이다. => 소프트웨어가 운영 환경에 도달했을 때 동작할 것이란 더 큰 확신을 주기 때문이다.
  - 하지만 실제로는 비용이 너무 늘어나 운영 환경 전체 복사본을 여러 개 실행할 만한 여력이 없는 경우가 많다.
  - 가능한 한 빨리 소프트웨어의 작동 여부를 파악하는 것이 중요하다.
- 개발자에게 더 가까운 환경은 빠른 피드백을 제공하도록 조정되고 '운영 환경과 같은' 환경이 아닐 수 있음을 의미한다.
  - 하지만 운영 환경에 가까워질수록 문제를 포착할 수 있게끔 최종 운영 환경과 점점 유사해지길 바랄 것이다.

<br/>

## 2. 마이크로서비스 배포의 원칙

- 배포하는 방법의 선택지가 너무 많으므로, 이 분야에서는 몇 가지 핵심 원칙을 정하는 것이 중요하다.

### 2-1. 격리 실행

- 마이크로서비스 인스턴스가 자체 컴퓨팅 자원을 가진 격리된 방식으로 실행하라. 근처에서 실행 중인 다른 마이크로서비스 인스턴스에 영향을 미치지 않도록 실행돼야 한다.
- 마이크로비스로 향하는 여정 초기에는 모든 마이크로서비스 인스턴스를 단일 머신(하나의 물리 머신이나 `가상 머신 virtual machine`)에 밀어 넣고 싶은 유혹을 받을 수 있다.
  - 순전히 호스트 관리 관점에서 보면 이 모델이 더 간단하다.
  - 한 팀이 인프라스트럭처를 관리하고 다른 팀이 소프트웨어를 관리하는 세상에서 인프라스트럭처 팀의 작업 부하는 종종 관리해야 하는 호스트 수에 좌우된다.
  - 더 많은 서비스를 하나의 호스트에 넣으면 서비스의 수가 증가해도 호스트 관리 워크로드는 증가하지 않는다.
- 하지만 이 모델에는 몇 가지 문제가 있다. 우선 모니터링이 더 어려워질 수 있다.
  - 예를 들어 CPU를 추적할 때는 한 서비스의 CPU를 다른 서비스와 별도로 추적해야 할까? 아니면 호스트 CPU 전체를 신경 써야 할까? 부작용도 피하기 어려울 것이다.
  - 한 서비스에 상당한 부하가 걸리면 시스템의 다른 부분에 사용할 수 있는 자원이 줄어들게 된다.
- 한 배포가 다른 배포에 영향을 미치지 않도록 보장하는 것은 추가적인 고민거리가 생겨나므로 서비스 배포도 다소 복잡해질 수 있다.
  - 예를 들어 각 마이크로서비스가 공유 호스트에 설치해야 하는 서로 다른(잠재적으로 모순되는) `의존성 dependency`을 필요로 한다면 어떻게 해야 할까?
- 이 모델은 또한 팀의 자율성을 저해할 수 있다.
  - 서로 다른 팀의 서비스가 동일한 호스트에 설치된다면, 누가 해당 서비스를 위해 호스트를 구성할까? 아마도 결국 중앙에 위치한 팀에서 처리하게 될 것이다.
  - 즉, 서비스를 배포하는 데 더 많은 조율이 필요해진다.
- 기본적으로 동일한 머신에 많은 마이크로서비스 인스턴스를 실행하면 전체적으로 마이크로서비스 핵심 원칙 중 하나인 독립적 배포 가능성이 크게 약화된다.
  - 따라서 마이크로서비스 인스턴스를 격리된 상태로 실행해야 한다.
  - 각 마이크로서비스 인스턴스는 자체적으로 격리된 실행 환경이 있으며, 각각에게 필요한 의존성을 설치할 수 있고 전용 자원도 가진다.
- 컨테이너화 기술이 합류하면서 격리된 실행 환경을 프로비저닝하기 위해 그 어느 때보다 많은 방법을 갖추게 됐다.
  - 컨테이너는 격리 정도는 더 약하지만, 비용 효율이 더 높고 프로비저닝도 훨씬 더 빠르다.
- AWS 람다나 Heroku와 같은 더 추상화된 플랫폼에 마이크로서비스를 배포하는 경우에도 이러한 격리가 제공된다.
  - 플랫폼의 자체 특성에 따라 마이크로서비스 인스턴스는 내부의 컨테이너나 전용 VM 내에서 실행된다고 예상할 수 있다.
- 일반적으로 컨테이너와 관련된 격리 기술은 마이크로서비스 워크로드를 위한 더욱 당연한 선택으로 여겨질 만큼 충분히 개선됐다.
  - 격리 측면에서 컨테이너와 VM은 대부분의 워크로드에서 '만족할 만한' 수준으로 그 차이가 줄어들었다.

### 2-2. 자동화 집중

- 마이크로서비스의 수가 증가함에 따라 자동화가 점점 더 중요해지고 있다. 고수준의 자동화를 가능하게 할 기술을 선택하는 데 집중하고 자동화를 문화의 핵심 부분으로 채택하라.
- 대부분 수동으로 운영 프로세스를 관리하고 있다면 더 많은 서비스로 인해 작업할 사람이 더 필요하다는 사실을 의미한다.
  - 따라서 자동화에 끊임없이 주력해야 한다. 자동화는 개발자의 생산성을 유지하는 방법이다.
  - 각 서비스나 서비스 그룹을 직접 프로비저닝할 기능을 제공하는 것은 그들의 삶을 편리하게 만드는 비결이다.
- 자동화를 가능하게 하는 기술을 고르는 것은 호스트를 관리하는 데 사용되는 도구에서 시작된다.
  - 가상 머신을 시작하거나 종료하는 코드를 작성할 수 있는가?
  - 작성한 소프트웨어를 자동으로 배포할 수 있는가?
  - 수작업 없이 데이터베이스 변경 사항을 배포할 수 있는가?
  - 마이크로서비스 아키텍처의 복잡성을 억제하려면 자동화 문화를 수용하는 것이 핵심이다.

### 2-3. 코드형 인프라스트럭처

- 자동화를 용이하게 하고 정보 공유를 촉진하는 인프라스트럭처 구성을 기술하라. 환경을 재구축할 수 도록 이 코드를 `소스 제어 source control`에 저장하라.
- `코드형 인프라스트럭처 infrastructure as code`는 `기계 가독형 코드 machine-readable code`를 사용해 인프라스트럭처를 구성하는 개념이다.
  - chef나 puppet 파일에 서비스 구성을 정의하거나 설정에 필요한 bash 스크립트를 작성할 수도 있다.
  - 하지만 어떤 도구를 사용하든 소스 코드를 사용해 시스템이 알려진 상태로 전환할 수 있다.
  - 논란이 있지만 코드형 인프라스트럭처의 개념은 자동화를 구현하는 하나의 방법으로 간주되기도 하며, 자동화를 수행하는 방법을 알려주는 것 자체로도 다룰 만한 가치가 있다.

### 2-4. 무중단 배포

- 독립적인 배포 가능성을 더욱 강화해 서비스 사용자(사람 또는 마이크로서비스)에게 다운 타임 없이 새 버전의 마이크로서비스를 배포할 수 있어야 한다.
- 무중단 배포 기능을 구현하면 마이크로서비스를 개발하고 배포하는 과정에서 큰 진보를 이룰 수 있다.
  - `무중단 zero-downtime` 배포를 하지 못한다면, 소프트웨어를 릴리스할 때 업스트림 소비자에게 잠재적 중단을 경고하도록 그들과 조율해야 할 수도 있다.
- 여기서는 릴리스를 수행할 때 업스트림 소비자가 전혀 알아채지 못하게 하는 것이 목표다.
  - 이를 가능하게 하는 것은 마이크로서비스 특성에 크게 좌우된다. 이미 마이크로서비스와 소비자 사이에 미들웨어가 지원하는 비동기식 통신을 사용하고 있다면 쉽게 구현할 수 있다.
- `롤링 업그레이드 rolling upgrade`와 같은 개념은 유용할 수 있으며 쿠버네티스와 같은 플랫폼을 사용하면 삶이 훨씬 편리해지는 영역 중 하나다.
  - 롤링 업그레이드를 사용하면 새 버전이 배포되기 전까지 마이크로서비스가 완전히 종료되지 않는다.
  - 대신 새 버전의 소프트웨어를 실행하는 새 인스턴스가 증가함에 따라 기존 마이크로서비스 인스턴스가 서서히 감소한다.
  - 하지만 무중단 배포에 도움이 될 용도만으로 쿠버네티스를 적용한다면 지나친 과잉 작업이 될 가능성이 높다.

### 2-5. 기대 상태 관리

- 마이크로서비스를 지정된 상태로 유지할 수 있는 플랫폼을 사용해 장애가 발생하거나 트래픽이 증가할 때 필요하다면 새로운 인스턴스를 시작한다.
- `기기 상태 관리 desired state management`는 애플리케이션을 위한 인프라스트럭처의 요구 사항을 수동으로 개입하지 않고도 유지 관리하는 기능이다.
  - 실행 중인 시스템이 원하는 기대 상태가 더 이상 유지되지 않는 방식으로 변경되면 기반 플랫폼은 시스템을 원하는 상태로 되돌리려고 필요한 단계를 수행한다.
- 기대 상태 관리의 장점은 플랫폼 스스로 원하는 상태를 유지하는 방법을 관리한다는 것이다.
  - 이는 개발과 운영을 담당하는 사람들이 정확히 일이 어떻게 진행되고 있는지 걱정할 필요가 없게 해준다.
  - 즉, 처음에 원하는 기대 상태를 올바르게 정의하는 데만 집중하면 된다.
  - 인스턴스가 죽거나 하부 하드웨어가 고장 나거나 데이터 센터가 중단되는 등의 문제가 발생하는 경우 사람이 개입하지 않고도 플랫폼이 문제를 처리할 수 있음을 의미한다.
  - 쿠버네티스는 이 개념을 수용한 도구.

#### 전제 조건

- 기대 상태를 관리하려면 플랫폼에서 마이크로서비스 인스턴스를 자동으로 시작하는 방법이 필요하다.
  - 따라서 마이크로서비스 인스턴스에 대한 완전히 자동화된 배포는 올바른 상태 관리를 위한 확실한 전제 조건이다.
  - 또한 인스턴스가 시작하는 데 드는 시간을 신중하게 생각해야 할 수도 있다.
  - 사용자 부하를 처리하기에 충분한 컴퓨팅 리소스가 있는지 확인하는 데 기대 상태 관리를 사용하고 있다면, 인스턴스가 죽을 때 교체 인스턴스를 사용해 가능한 한 신속하게 공백을 메우길 원할 것이다.

#### 깃옵스

- `워브웍스 Weaveworks`가 객척한 비교적 최근의 개념인 `깃옵스 GitOps`는 기대 상태 관리와 코드형 인프라스트럭처의 개념을 통합한다.
  - 깃옵스는 원래 쿠버네티스와 작업하는 상화에서 고안됐으며 다른 사람들이 이전에 사용했던 워크플로를 설명하는 것은 틀림없지만 관련된 도구에 중점을 둔다.
- 깃옵스를 사용하면 인프라에 대해 원하는 기대 상태를 코드로 정의하고 소스 제어에 저장할 수 있다.
  - 기대 상태가 변경되면 일부 도구는 업데이트된 기대 상태가 실행 중인 시스템에 반영되도록 한다.
  - 이와 같은 아이디어는 개발자에게 애플리케이션 작업을 위한 간소화된 워크플로를 제공하기 위한 것이다.
- `플럭스 Flux`와 같은 도구를 사용하면 이러한 개념을 훨씬 더 쉽게 수용할 수 있다.
  - 물론 도구를 사용하면 기존의 작업 방식을 쉽게 변경할 수 있지만, 도구 때문에 새로운 방식을 강요할 수는 없다.
  - 달리 말하면 플럭스(또는 다른 깃옵스 도구)가 있다고 해서 기대 상태 관리나 코드형 인프라스트럭처를 수용하는 것은 아니라는 뜻이다.
- 쿠버네티스를 사용하고 플럭스와 같은 도구와 이 도구가 추진하는 워크플로를 채택해 기대 상태 관리 및 코드형 인프라스트럭처와 같은 개념을 도입하는 속도를 높일 수 있다.

<br/>

## 3. 배포 방법

- 마이크로서비스 워크로드에 사용할 수 있는 방식과 도구에는 많은 선택지가 있다.
  - 마이크로서비슥가 격리된 방식으로 실행되고 다운타임이 없는 이상적 방식으로 배포되는 것이 이상적.
  - 또한 자동화 문화를 수용하고 인프라스트럭처 및 애플리케이션 구성을 코드로 정의하며 이상적으로 기대 상태도 관리할 수 있는 도구를 선택.

### 3-1. 물리 머신

- 드문 방법.
- 사용자와 하부 하드웨어 사이에 가상화 또는 컨테이너화 계층이 없음을 의미하며, 이 방식은 몇 가지 다른 이유에서 점점 덜 보편적이게 됐다.
- 우선 물리 하드웨어에 직접 배포하면 자산 전체 활용도가 낮아질 수 있다.
  - 한 물리 머신에 하나의 마이크로서비스 인스턴스가 실행 중이고 하드웨어에서 제공하는 CPU, 메모리, I/O를 절반만 사용한다면 나머지 자원은 낭비된다.
  - 이런 문제로 대부분의 컴퓨팅 인프라스트럭처는 가상화 됨.

### 3-2. 가상 머신

- 기존 물리 머신을 더 작은 가상 머신으로 분할할 수 있게 함으로써 데이터 센터를 변화시켰다.
- 근본적으로 가상화를 사용하면 기본 머신을 여러 개의 더 작은 `가상 virtual` 머신으로 분할할 수 있다.
  - 이 가상 머신은 내부에서 실행되는 소프트웨어에 보통의 서버처럼 동작한다.
  - 하부의 CPU, 메모리, I/O, 스토리지에 해당하는 기능 일부를 각 가상 머신에 할당할 수 있으며, 이렇게 함으로써 마이크로서비스 인스턴스를 위해 더욱 격리된 실행 환경을 하나의 물리 머신에 밀어 넣을 수 있다.
- 각 VM은 매우 훌륭한 격리 수준이 보장된다.
  - 하지만 하부 머신이 망가지면 여러 마이크로서비스 인스턴스가 손실되는 문제는 여전히 있다.

#### 가상화 비용

- 점점 더 많은 가상 머신을 같은 하부 하드웨어에 넣을수록 VM 자체에서 가용한 컴퓨팅 리소스 측면에서 오히려 자원이 늘었음에도 효용이 떨어지는 현상 (`수확 체감 diminishing returns`)이 나타날 것이다.
- VM 가상화(`타입 2 가상화 type 2 virtualization`) vs 컨테이너 기반 가상화
- Type 2 Virtualization
  - VM은 물리적 인프라스트럭처에는 호스트 운영체제가 있다. 이 운영체제에서는 두 가지 중요한 임무를 맡은 `하이퍼바이저 hypervisor`라는 것을 실행하는데 하이퍼바이저의 두 가지 임무는 다음과 같다.
  - (1) CPU와 메모리 같은 자원을 가상 호스트에 물리 호스트로 매핑한다. (2) 제어 계층 역할을 하며 가상 머신 자체를 조작할 수 있게 한다.
  - VM 내부에는 완전히 다른 호스트처럼 보이는 것이 있으며, 이 호스트들은 자체 커널로 자체 운영체제를 실행할 수 있다.
  - 호스트는 하이퍼바이저에 의해 거의 밀폐된 머신으로 간주돼 하부의 물리 호스트와 다른 가상 머신에서 격리된 상태로 유지된다.
  - 이 가상화의 문제는 하이퍼바이저가 작업을 수행하기 위해 자원을 별도로 확보해야 한다는 것이다. 하이퍼바이저가 관리하는 호스트가 많을수록 더 많은 자원이 필요하며, 특정 시점에서 이 오버헤드는 물리 인프라스트럭처를 추가 분할하는 데 제약이 된다.

#### 마이크로서비스에 적합한가?

- 가상 머신은 격리 측면에서 매우 훌륭하지만 비용이 든다.
- 그동안 많은 조직에서 대규모 마이크로서비스 시스템을 실행하는 데 가상 머신을 사용해 큰 효과를 거둬왔다.

### 3-3. 애플리케이션 컨테이너

- 컨테이너는 서버 측 소프트웨어 배포에서 지배적 개념이 됐으며, 많은 사람에게 마이크로서비스 아키텍처를 패키징하고 실행하기 위한 실질적인 선택지가 됐다.
- 도커에 의해 대중화되고 쿠버네티스와 같은 지원 컨테이너 오케스트레이션 플랫폼과 결합된 컨테이너 개념은 대규모 마이크로서비스 아키텍처를 실행하기 위해 찾는 선택지가 됐다.

#### 다른 방식의 격리

- 컨테이너는 유닉스 계열의 운영체제에서 처음 등장.
- 동일한 머신에서 실행되는 컨테이너는 동일한 하부 커널을 사용한다.
  - 프로세스를 직접 관리하는 대신 컨테이너를 전체 시스템 프로세스 트리의 하위 트리에 대한 추상화로 생각할 수 있으며 커널이 모든 힘든 작업을 수행한다.
  - 이러한 컨테이너에는 커널이 처리하는 물리적 자원이 할당될 수 있다.
- 컨테이너를 실행하는 호스트에 대한 스택 다이어그램
  1. 하이퍼바이저가 필요 없다.
  2. 컨테이너에 커널이 없어 보이지만, 사실 하부 머신의 커널을 사용한다.
- 컨테이너를 사용하면 하이퍼바이저가 필요하지 않아 자원을 절약할 수 있다.
  - 리눅스 컨테이너는 비대한 가상 머신보다 프로비저닝이 훨씬 바르다.
  - VM이 시작하는 데 몇 분이 걸리는 경우는 드물지 않지만, 리눅스 컨테이너를 사용하면 몇 초면 된다.
  - 리소스 할당 측면에서 컨테이너 자체를 더 세밀하게 제어할 수 있으므로 하부 하드웨어를 최대한 활용하도록 훨씬 쉽게 설정을 조정할 수 있다.

#### 완전하지는 않다

- 하지만 리눅스 컨테이너가 문제없지는 않다.
  - 외부 세계를 라우팅할 수 있는 방법이 필요하며, 이는 많은 하이퍼바이저가 일반 가상화에서 수행하는 작업이다.
  - LXC와 같은 초기 기술을 사용할 대는 이 작업을 직접 해야 했다.
- 명심해야 할 또 다른 점은 리소스 관점에서 이러한 컨테이너가 격리된 것으로 간주될 수 있다는 사실이다.
  - 제한된 CPU, 메모리 등을 각 컨테이너에 할당할 수 있지만 가상 머신 격리 수준과 반드시 동일하지는 않다.
  - 또는 이 문제를 별도의 물리 머신을 사용함으로서 해결할 수 있다.

#### 윈도 컨테이너

- 윈도 사용자는 컨테이너가 윈도 운영체제에서 받아들여지지 않았기 때문에 리눅스를 사용하는 동시대 사람들을 부러워했던 것처럼 보인다.
  - 하지만 컨테이너가 완전히 지원되는 개념으로 바뀌면서 상황이 달라졌다.
  - 윈도 크기는 너무 커서 이미지 크기뿐 아니라 이미지를 실행하는 데 필요한 리소스 측면에서도 컨테이너가 매우 무거워졌다.

#### 도커

- 도커 이전에는 컨테이너에 대한 '이미지' 개념이 없었다.
  - 이러한 개념은 컨테이너 작업을 위한 훨씬 더 좋은 도구들과 함께 컨테이너를 훨씬 더 쉽게 사용하는 데 도움을 주었다.
- 도커 이미를 추상화하면 마이크로서비스 구현 방법에 대한 세부 정보를 숨길 수 있어 유용하다.
  - 우리는 마이크로서비스용 빌드가 빌드 산출물로 도커 이미지를 생성하고 그 이미지를 도커 레지스트리에 저장하도록 했다.
  - 도커 이미지의 인스턴스를 시작하면 사용되는 기본 기술(Go, Python, Node.js)에 관계없이 해당 인스턴스를 관리하는 일반적인 도구 집합이 있다.

#### 마이크로서비스에 대한 적합성

- 매우 적합
- 격리성을 확보할 수 있었지만 감당할 수 있는 비용.
- 하부 기술을 숨겨 다양한 기술 스택을 혼합 가능.
- 하지만 기대 상태 관리와 같은 개념을 구현하려면 이를 처리하기 위해 쿠버네티스와 같은 것이 필요.

### 3-4. 애플리케이션 컨테이너

- `웹로직 Weblogic`, `톰캣 Tomcat` 과 같은 것으로 배포하는 데 익숙하다면, 여러 개의 개별 서비스나 애플리케이션이 단일 애플리케이션 컨테이너에 존재하는 모델을 잘 알고 있을 것이다.
  - 애플리케이션 컨테이너도 단일 호스트에 상주한다.
  - 이 개념은 서비스가 상주하는 애플리케이션 컨테이너가 여러 인스턴스를 함께 그룹화하는 클러스터링 지원, 모니터링 도구 등과 같은 관리 용이성 측면에서 이점을 제공
- 여러 단점
  1. 필연적으로 기술 선택을 제한. 기술 스택을 받아들여야 한다.
  2. 제공하는 기능의 가치에도 의문

### 3-5. Paas

- Platform as a Service
- 단일 호스트보다 더 고수준의 추상화에서 작업하게 된다.
  - 일부는 자바 WAR 파일이나 루비 gem과 같은 특정 기술의 산출물을 가져와서 자동으로 프로비저닝하고 실행하는 데 의존
  - 시스템 확장 및 축소를 투명하게 처리하려고 시도.

### 3-6. Faas

- Function as a Service
- 지난 몇 년 동안 쿠버네티스에 근접한 유일한 기술은 서비리스다.
  - 하부의 컴퓨터가 중요하지 않고 다양한 기술을 가진 호스트를 포괄하는 상위 용어.

> - `서버리스 serverless`는 더 이상 서버와 관련 없다는 의미가 아니다. 단순히 개발자가 더 이상 서버에 대해 그렇게 많이 생각할 필요가 없다는 것을 의미한다.
> - 컴퓨팅 자원은 물리적 용량이나 제한을 관리할 필요 없이 서비스로 사용된다. 서비스 공급자는 점점 더 서버, 데이터 저장소 및 기타 인프라스트럭처 자원을 관리하는 책임을 갖는다.
> - 개발자는 자신들의 오픈 소스 솔루션을 설정할 수 있지만, 이는 서버, 큐, 부하를 관리해야 한다는 것을 의미한다.
> 켄 프롬, '소트프웨어와 앱의 미래는 왜 서버리스인가?'

- FaaS는 서버리스의 주요 부분이 됐으므로 많은 경우에 두 용어는 서로 맞바꿔 사용할 수 있다.
  - 이는 데이터베이스, 큐, 스토리지 솔루션 등과 같은 다른 서버리스 제품의 중요성을 간과하게 되므로 안타까운 일이다.
  - 그럼에도 불구하고 FaaS가 논쟁을 지배하고 있다는 것은 FaaS가 얼마나 큰 관심을 불러일으키고 있는지를 말해준다.
- AWS Lambda.
  - 어떤 코드(함수)를 배포한다.
  - 해당 코드는 코드를 트리거하는 무언가 발생할 때까지 휴면 상태다.
  - 트리거가 어떤 것인지 결정하는 일은 사용자의 몫이다.
  - 예를 들면 특정 위치에 도착하는 파일, 메시지 큐에 나타나는 항목, HTTP를 통해 들어오는 호출 등이 될 수 있다.
- 함수가 트리거되면 실행되고 완료되면 종료된다.
  - 하부 플랫폼은 요구에 따라 이러한 기능을 시작하고 종료하며 함수의 동시 실행을 처리하므로 적절한 경우 한 번에 여러 복사본을 실행할 수 있다.
  - 사용하는 만큼만 비용을 지불하면 된다.

#### 제한 사항

- FaaS 구현은 이면에서 일종의 컨테이너 기술을 사용하고 이 기술은 숨겨져 있다.
  - 컨테이너 생성 걱정 X, 일부 패키징될 형태의 코드를 제공하기만 하면 된다.
  - 하지만 이는 정확히 실행할 수 있는 것에 대한 제어가 부족하다는 것을 의미한다. 결과적으로 개발자가 선택한 언어를 지원하려면 FaaS 제공자가 필요하다.

#### 문제점

1. `시작 시간 spin-up time` 개념을 해결하는 것이 중요하다.
  - 개념적으로 함수는 필요하지 않으면 전혀 실행되지 않는다.
  - 일부 런타임의 경우 새로운 런타임을 가동하는 데 오랜 시간이 걸리며, 이를 `콜드 스타트 cold start` 시간이라고 한다.
  - 적어도 AWS는 런타임들이 `예열 warm` 상태로 유지되므로 인입된 요청은 이미 시작돼 실행 중인 인스턴스에서 처리된다.
2. 함수의 동적 확장 측면에서 실제로 문제가 될 수 있다.
  - 함수의 최대 동시 호출 수에 대한 엄격한 제한. 주의 깊게 기록해야 할 수 있다.

#### 마이크로서비스와 매핑

- **마이크로서비스당 함수 매핑**
  - 단일 마이크로서비스 인스턴스는 단일 함수로 배포될 수 있다.
  - 비용 서비스를 REST 기반 마이크로서비스로 구현했다면 다양한 자원이 노출됐을 것.
  - 이 모델을 사용하면 이러한 자원에 대한 요청이 동일한 진입점을 통해 들어오므로, 인바운드 요청 경로를 기반으로 인바운드 후출을 적절한 기능 부분으로 돌려야 한다.
- **애그리거트당 함수 매핑**
  - 인스턴스를 더 작은 기능으로 어떻게 나눌 수 있을까?
  - 도메인 기반 설계를 사용하고 있다면 이미 애그리거트를 명시적으로 모델링했을 것이다.
  - 모든 로직이 함수 내에 완전히 포함돼 애그리거트의 수명주기 관리를 일관되게 구현하는 것이 더 수월해진다.
  - 이 모델을 사용하면 마이크로서비스 인스턴스가 더 이상 단일한 배포 단위로 매핑되지 않는다.
  - 이론상 서로 독립적으로 배포할 수 있는 여러 가지 함수로 구성된 논리적 개념에 가깝다.
- **더욱 세분화**
  - 더 작게 만들고 싶다면 애그리거트 당 기능을 더 작은 조각으로 나누고 싶은 유혹이 따른다.
  - 하지만 신중하게 결정 => 함수가 폭발적으로 증가할 수 있을 뿐 아니라 애그리거트의 힉샘 원칙 중 하나를 위한하기 때문
  - 애그리거트 자체의 일관성을 더 잘 관리하기 위해 애그리거트를 단일한 단위로 취급해야 한다.

#### 향후 전망

- 대부분의 개발자가 결국 사용하게 될 플랫폼 형태.
- FaaS 제품에 점점 더 많은 작업이 진행됨에 따라 주요 클라우드 공급자가 제공하는 FaaS 솔루션을 직접 사용할 수 없는 사람들도 점점 더 새로운 작업 방식을 활용하게 될 것.

<br/>

# 참고 자료

- 마이크로서비스 아키텍처 구축, 샘 뉴먼 지음
