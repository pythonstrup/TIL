# 5장 트랜잭션 처리와 복구

- DBMS에서 트랜잭션이란 하나의 논리적 작업 단위를 의미
  - 여러 작업을 한 단계로 표현하는 방법
  - 작업은 데이터베이스의 읽기와 쓰기를 모두 포함
- 모든 데이터베이스 트랜잭셔은 ACID을 보장한다.

> #### 원자성 Atomicity
> - 트랜잭션은 더 작은 단계로 나눌 수 없다.
> - 트랜잭션과 관련된 작업은 모두 실행되거나 모두 실패해야 한다. 부분적으로 실행될 수 없다.
> - COMMIT or ROLLBACK(ABORT)

> #### 일관성 Consistency
> - 애플리케이션이 제어하는 속성
> - 참조 무결성 등의 제약 조건을 위반하지 않고 데이터베이스를 하나의 유효한 상태에서 또 다른 유효한 상태로 변경한다.
> - 일관성은 가장 약하게 정의된 성질로, 데이터베이스가 아닌 사용자가 제어할 수 있는 유일한 속성이다.
>   - ex) 재고가 10개일 때, 고객이 15개를 주문하는 경우 => 재고는 0 이상이어야 한다는 무결성 제약 조건에 위배되어 되돌려야 한다.
> - 참고로 CAP 이론에서 말하는 일관성과는 의미가 상당히 다르다고 하다.(11장)

> #### 격리성 Isolation
> - 동시에 수행되는 여러 트랜잭션은 다른 트랜잭션이 존재하지 않는 것처럼 서로 간섭없이 수행돼야 한다.
> - 많은 데이터베이스는 성능상의 이유로 약한 `격리 수준 isolation level`을 사용한다.
> - 동시성 제어 방식에 따라 트랜잭션의 변경 내용 중 일부가 동시 수행 중인 다른 트랜잭션에 노출될 수도 있고 노출되지 않을 수도 있다.

> #### 지속성 Durability
> - 트랜잭션 커밋 후 디스크에 저장된 데이터베이스의 상태는 시스템이 중단되거나 정전 또는 시스템 장애가 발생해도 그대로 유지돼야 한다.

- 잠금이 요청되면 `공유 shared` 혹은 `배타적 exclusive` 잠금 모드로 해당 리소스를 이미 소유하고 있는지 확인
  - 요청자가 접근 권한 있다면 접근 허용. 단 동시에 한 개의 트랜잭션만 소유 가능 => 다른 트랜잭션은 기다려야 한다는 얘기
  - 잠금이 해제되면 잠금 매니저는 대기 중인 트랜잭션에 이 사실을 알린다.
- `페이지 캐시 page cache`는 영구 저장소(디스크)와 스토리지 엔진 사이에서 중개자 역할을 한다.
  - 메인 메모리의 변경 사항을 저장하고 영구 저장소와 동기화되지 않은 페이지를 캐시한다.
  - 모든 데이터베이스 상태에 대한 변경 사항은 우선 페이지 캐시에 저장된다.
- `로그 매니저`는 영구 저장소와 동기화되지 않은 페이지 캐시의 내용이 손실되지 않도록 작업 히스토리를 저장한다.
  - 로그를 기반으로 부팅 시 작업을 재수행하고 마지막 캐시 상태를 재구성한다. 중단된 트랜잭션이 변경한 내용을 `되돌릴 undo` 때에도 로그를 사용한다.
- 분산(멀티파티션) 트랜잭션은 추가적인 조정과 원격 실행이 필요하다. (13장)

----

## 버퍼 관리

- 영구 저장소 접근 횟수를 줄이기 위해 페이지를 메모리에 캐시, 스토리지 계층에서 캐시된 페이지를 재요청하면 캐시에서 반환
- 다른 프로세스가 디스크에 저장된 같은 페이지를 변경하지 않았다면 메모리에 캐시된 페이지를 재사용할 수 있다.
  - 이와 같은 방식을 `가상 디스크 virtual disk`라고 부르기도 한다.
  - 가상 디스크 읽기 작업 -> 메모리 접근 -> (메모리에 없으면) 디스크 접근
  - 이 개념의 더 일반적인 명칭. `버퍼 풀 buffer pool` (하지만 버퍼 풀의 주된 목적이 버퍼에 저장된 데이터는 공유하지 않고 버퍼 생성과 미사용 버퍼의 재사용으로 혼동되기 때문에 `페이지 캐시`라는 용어가 더 나음)
- 페이지 캐시는 데이터베이스에서만 사용되는 개념은 아니다.
  - 운영체제도 I/O `시스템 호출 syscall`의 성능을 높이기 위해 디스크에 저장된 내용을 비어 있는 메모리 세그먼트에 캐시한다.
- 아직 캐시되지 않은 페이지를 디스크에서 메모리로 복사하는 작업을 `페이징 paging`이라고 한다.
  - 아직 디스크로 플러시되지 않은 변경된 페이지는 `더티 페이지 dirty page`라고 표현한다.
- 페이지 캐시는 순서를 고려하지 않고 페이지를 빈 슬롯에 복사한다.
  - 따라서 디스크와 메모리에서 페이지가 정렬되는 방식 사이에는 연관성이 없다.
- 페이지 캐시의 주요 기능
  - 페이지 내용을 메모리에 캐시
  - 디스크에 저장된 페이지에 대한 변경 사항을 함께 버퍼링하고 캐시된 페이지에 반영
  - 캐시되지 않은 데이터가 요청된 경우 메모리에 공간이 충분하다면 페이징하고 캐시된 버전을 반환
  - 캐시된 페이지가 요청된 경우 메모리에서 반환
  - 메모리에 새로운 페이지 추가 -> 공간 없음 -> 일부 페이지를 만료시키고 플러시

### 캐싱

- 버퍼에 대한 변경 사항은 디스크에 쓰기 전까지 메모리에 남겨둔다.
- 동기화는 메모리에서 디스크로 플러시하는 단방향 작업.
- 페이지를 캐시하면 알고리즘을 수정하거나 객체를 메모리에 `실체화 materialize`하지 않고 트리의 일부를 메모리에 저장할 수 있다.
  - 간단하게 디스크에 접근하는 대신 페이지 캐시를 요청하면 된다.
- 스토리지 엔진이 특정 페이지를 요청하면 우선 캐시된 버전이 있는지 확인하고 있을 경우 반환한다.
  - 없다면 논리적 페이지 주소 또는 페이지 번호를 물리적 주소로 변환해 해당 페이지를 메모리로 복사하고 반환한다.
  - 이때 해당 페이지가 저장된 버퍼는 `참조 reference` 상태라고 표현.
  - 작업이 끝나면 스토리지 엔진은 해당 페이지를 페이지 캐시에 반환 또는 `참조 해제 dereference`해야 한다.
  - 페이지를 고정시키면 페이지 캐시에서 제거되지 않는다.
- 페이지가 변경된 경우에는 페이지에 더티 플래그를 설정
  - 더티 플래그는 해당 페이지가 디스크와 동기화되지 않았고 지속성을 위해 디스크로 플러시돼야 한다는 것을 의미

### 캐시 만료

- 캐시된 데이터가 많을수록 더 많은 읽기 요청을 영구 저장소에 접근하지 않고 처리할 수 있다.
  - 나아가 같은 페이지에 대한 변경 사항을 더 많이 같이 버퍼할 수 있다.
  - 하지만 페이지 캐시의 크기는 한정적 -> 새로운 페이지를 저장하기 위해 오랜된 페이지는 제거해야 한다.
  - 페이지가 동기화됐고 고정 또는 참조 상태가 아니라면 바로 제거될 수 있다.
  - 더티 페이지는 제거되기 전에 먼저 플러시해야 한다.
  - 참조 상태의 페이지는 사용이 끝나기 전까지는 제거될 수 없다.
- 페이지를 제거할 때마다 디스크로 플러시하면 성능 저하
  - 따라서 일부 데이터베이스는 별도의 백그라운드 프로세스가 제거될 가능성이 높은 더티 페이지를 주기적으로 디스크로 플러시
  - ex) PostgreSQL의 `백그라운드 플러시 라이터 background flush writer`
- 지속성 보장
  - 데이터 손실을 방지하기 위해 `체크포인트 checkpoint` 프로세스가 플러시 시점을 제어.
  - 체크포인트 프로세스는 `선행 기록 로그 WAL`와 페이지 캐시의 싱크가 맞도록 조정
  - 오직 플러시가 완료되었으며 캐시된 페이지와 관련된 로그만 WAL에서 삭제될 수 있다.

### 페이지 고정

- 모든 읽기와 쓰기 작업에서 디스크 I/O가 발생하는 시스템은 사실상 사용이 불가능.
- 페이지를 캐시에 가둬 두는 것을 `고정 pinning`한다고 표현.
  - 고정된 페이지는 메모리에 더 오랜 시간 동안 유지되기 때문에 디스크 접근 횟수가 줄어들고 성능에 도움이 된다.
- 트리의 하위 레벨에는 상위 레벨보다 노드 수가 월등히 많기 때문에 상위 레벨 노드는 트리 전체에서 극히 일부분에 해당
  - 따라서 상위 레벨 노드를 메모리에 고정시키고 나머지 노드는 요청 시 페이징해도 된다.
  - 이 방식은 쿼리 요청마다 디스크에 h번 접근하지 않아도 되고, 캐시되지 않은 하위 레벨 노드만 디스크에서 읽는다. (h는 트리의 높이)
- 서버트리에 대해 수행된 작업으로 인해 서로 상충되는 구조 변경이 연속해서 발생할 수 있다.
  - ex) 연속된 삭제 작업이 노드를 병합하고 뒤를 이어 다른 쓰기 작업이 같은 노드를 다시 분할하는 상황
  - 마찬가지로 다른 서브트리에서 전파된 구조 변경으로 인해 같은 상황이 발생할 수도 있다.
  - 변경 사항을 디스크에 바로 쓰는 대신 메모리에 모아뒀다가 일괄 적용하면 이와 같은 상황을 방지하고 디스크 접근 횟수와 작업 비용을 줄일 수 있다.

### 페이지 교체 알고리즘

- 메모리는 부족한 리소스. => 일부 페이지를 만료시킬 수밖에 없다.
- 캐시 페이지는 `만료 정책 eviction policy`에 따라 캐시에서 제거된다.
- 페이지 교체 알고리즘 => 페이지 캐싱의 성능을 결정하는 중요한 요인

#### FIFO와 LRU

- 가장 간단한 방법. 선입선출 `FIFO(First In First Out)`
- FIFO를 확장한 `LRU(Least-Recently Used)`
  - 페이지가 재요청되면 처음 페이징된 것처럼 큐의 끝에 추가
  - LRU 기반의 다양한 교체 알고리즘: `2Q(Two-Queue) LRU`, `LRU-K`

#### CLOCK 알고리즘

- LRU의 대안으로 사용되는 `CLOCK` 알고리즘
  - 단순하고 캐시 친화적이며 동시성을 지원한다.
- `CLOCK-sweep`: 페이지에 대한 참조와 접근 여부를 나타내는 비트를 원형 버퍼에 저장. 페이지가 요청될 때마다 해당 페이지의 접근 비트를 1로 설정. 원형 버퍼를 순회하면서 접근 비트를 확인한다.
  - 접근 비트가 1이지만 페이지가 참조 중이 아니라면 접근 비트를 0으로 설정하고 다음 페이지 확인
  - 접근 비트가 0이면 해당 페이지를 제거 대상으로 선정, 만료 작업을 스케줄링
  - 참조 중인 페이지는 그대로 유지. 참조 중인 페이지의 접근 비트는 0이 될 수 없다.

#### LFU

- Least-Frequently Used
- TinyLFU는 페이징 시점이 아닌 요청 빈도를 고려해 페이지의 만료 여부를 결정하는 요청 빈도 기반 페이지 교체 알고리즘이다. 자바 라이브러리 카페인이 사용하는 방식이다.
- TinyLFU는 페이지를 다음 중 하나의 큐에 저장
  - `등록 큐 Admission Queue`: LRU 알고리즘 기반으로 새로 추가된 페이지를 저장
  - `관찰 큐 Probation Queue`: 제거될 확률이 높은 페이지를 저장
  - `보호 큐 Protected Queue`: 큐에 오랫동안 남아 있을 페이지를 저장
- 요청 빈도가 높은 페이지를 관찰 큐로 옮기고 다시 요청되면 보호 큐로 옮긴다. 보호 큐가 가득 차면 일부 페이지를 다시 관찰 큐로 옮긴다.

---


