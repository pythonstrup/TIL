# 8장 분산 시스템 개요

- 분산 시스템과 단일 노드 시스템의 본질적인 차이?

## 동시 수행

<img src="img/distributed_system01.png">

- 동시성이라는 분산 시스템의 첫 번째 문제.
  - 동시성을 지원하는 프로그램은 모두 분산 시스템의 성격을 따른다.
  - 스레드는 공유된 자원에 접근하고 개별적으로 연산을 수행한 뒤 결과를 다시 공유 변수에 쓴다.
- 수행 단계를 정확하게 정의하고 가능한 결과의 수를 줄이기 위해서는 `일관성 모델 consistency model`이 필요하다.
  - 작업 수행 순서 정의, 다른 참가자가 순서를 알 수 있도록 해줌.
  - 시스템 상태의 종류를 제한하거나 완화할 수 있다.

> #### 동시성과 병렬성
> - 동시 수행: 한 대의 커피 머신에 두줄을 세우는 것
> - 병렬 수행: 두 대의 커피 머신에 두 줄을 세우는 것
> - 하지만 대부분의 경우 시스템이 여러 개의 스레드를 병렬로 실행하는 것을 동시성이라고 표현한다. 병렬성이라는 용어는 거의 사용하지 않는다.

## 분산 시스템의 자원 공유

- 데이터베이스에 대한 동시 요청 문제를 해결한다고 해도 모든 프로세스의 동기화를 보장할 수 없다.
- 데이터베이스에 접근하기 위해 프로세스는 전송 매체를 통해 메시지를 주고받아 상태를 쿼리하거나 수정해야 한다.
  - 하지만 오랫동안 응답을 받지 못한다면? -> 우선 오랜 시간에 대한 정의 필요
  - 이를 위해 통신이 완전히 비동기적인지 또는 일부 타이밍 가정이 있는지 여부를 나타내는 `동기성 synchrony`의 관점에서 시스템을 설명해야 한다.
  - 타이밍 가정이 있다면 타임아웃과 재시도 기능을 사용할 수 있다.
- 데이터베이스 응답 없음?
  - 과부화 상태? 사용할 수 없음? 느림? 네트워크에 문제? => 정확한 원인을 알 수 없다. 시스템 장의 특성.
  - 따라서 장애를 해결할 수 있는 방법을 찾기 전에 발생할 수 있는 장애 유형을 나타내는 `장애 모델 failure model`을 정의해야 한다.
- `내겸할성 fault tolerance`은 시스템의 신뢰성과 장애 발생 시 정상적으로 작동할 수 있는지 여부를 나타내는 속성이다.
  - 시스템 장애는 불가피 -> 단일 장애 지점 제거. 시스템의 `다중화 redundancy` -> 여러 복사본의 동기화 문제

## 분산 컴퓨팅의 오류

- 모든 위기 시나리오를 상황에 맞게 대처할 수 있는 시스템을 구축해야 한다.
  - 연결이 안정적이라도 원격 서버 호출이 로컬 호출보다 빠를 수 없다.
  - Latency에 대한 가정은 최소화해야 하지만 Latency가 0이라고 가정해서는 안 된다.
  - 메시지가 상대 서버에 도달하는 과정에서 여러 소프트웨어 계층과 광케이블 같은 물리적 매체를 통과한다.
  - 이 모든 과정은 즉각적이지 않다.
- 교환된 메시지의 수와 속도, 크기를 늘리거나 네트워크에 새로운 프로세스를 추가할 때 대역폭이 무한하다는 가정은 옳지 않다.

## 프로세싱

- 원격 프로세스 -> 즉각적이라고 가정할 수 없다.
  - 원격 프로세스의 로컬 프로세싱도 즉각적이지 않기 때문에 네트워크 레이턴시를 고려하는 것도 충분하지 않다.
- 나아가 메시지가 전달되는 즉시 프로세싱이 시작된다는 보장도 없다.
  - 작업을 우선 원격 서버의 대기열에 등록하고 이전에 도착한 메시지가 모두 처리될 때까지 기다려야 할 수 있다.
- 노드는 물리적으로 위치가 가깝거나 멀 수 있으며 CPU의 종류와 RAM의 크기, 디스크 종류, 소프트웨어 버전 및 환경 설정이 다를 수 있다.
  - 병렬로 처리? -> 전체 작업 속도 = 속도가 가장 느린 원격 서버의 속도
- 큐의 용량은 제한적 -> 요청을 계속 쌓는 것은 시스템에 아무런 도움이 되지 않는다.
  - `백프레셔 Backpressure` 알고리즘은 프로듀서가 컨슈머가 요청을 처리할 수 있는 속도보다 더 빠른 속도로 메시지를 발행하는 경우 프로듀서의 속도를 의도적으로 늦추는 알고리즘이다.
  - 분산 시스템에서 가장 인정받지 못하고 사용되지 않는 알고리즘 -> 보통 임시방편
- 큐의 용량을 늘리는 것은 아무런 영향도 없다. -> 오히려 레이턴시를 증가시킬지도.
- 일반적으로 프로세스에서 로컬 큐를 사용하는 이유
1. `분리 decoupling`: 메시지 수신과 처리를 시간적으로 분리하고 독립적으로 수행
2. `파이프라이닝 pipelining`: 서로 다른 단계에 있는 요청은 각각 독립된 서브시스템이 처리. 메시지를 수신하는 서브시스템은 이전 메시지가 완전히 처리될 때까지 블록하지 않아도 된다.
3. `일시적 급증 부하 처리`: 시스템 부하는 일정하지 않다. 레이턴시 = 큐에서 대기하는 시간에 비례. 일반적으로 요청을 실패했다고 응답하고 재시도하게 만드는 것보다는 훨씬 낫다.

- 작업량이 비교적 일정하다면 작업 처리 시간과 큐에 머무르는 평균 시간을 측정해 큐의 크기를 조정한다.
  - 처리량은 늘리고 레이턴시는 허용 가능한 범위 내로 유지해야 한다.

## 클럭과 시간

> 시간은 환상이다. 점심시간은 두 배로 그렇다.
> - 포드 프레펙트, "은하수를 여행하는 히치하이커를 위한 안내서"

- 두 서버의 클럭이 동기화됐다는 가정은 위험.
- 데이터를 수집하고 집계할 때 전달받은 타임스탬프에 의존하지 않고 참가자 사이의 시간 차이의 이해하고 알맞게 시간을 정규화해야 한다.
  - 참가자가 정확한 시간을 제공하지 않는 이상 동기화 또는 순서화에 타임스탬프를 사용하면 안 된다.
  - 물론 전달받은 시간을 완전히 무시하라는 의미 X -> 결국 모든 동기 시스템의 타임아웃은 로컬 클럭에 의존
- 프로세스 간의 시간 차이와 메시지를 전달하고 처리하는 데 소요되는 시간을 항상 고려
  - `일부 장애 감지 failure-detection` 알고리즘은 공유된 클럭에 의존하고 `클럭 차이 clock drift`가 항상 허용된 범위 내에 있다고 가정.
- 클럭 동기화는 쉽지 않다는 사실 + 현재 시간은 항상 바뀐다는 점을 기억.
  - 시간 제공자와 타임스탬프가 의미하는 정확한 순간을 이해하는 것이 중요하다.
- 클럭이 단조 클럭인지 여부와 예정된 시간 관련 작업 사이에 시간 차이가 얼마나 발생할 수 있는지 아는 것은 많은 도움이 될 수 있다.

## 상태 일관성

- 분산 알고리즘은 상태에 대한 일관성을 완벽하게 보장하지 않는다.
  - 일부는 제약 조건이 엄격하지 않고 복제 노드 간의 상태 차이를 허용하며 `충돌 해결 conflict resolution`과 `읽기 중 데이터 복구 방식 read-time data repair`을 통해 상태 차이를 해결한다.
- `결과적 일관성 eventual consistency`을 보장하는 분산 시스템에는 읽기 중에 노드 `쿼럼 quorum`(정족수)을 쿼리해 복제 노드 사이의 상태 불일치를 해결하는 로직이 있을 수 있다.
  - 하지만 데이터베이스 스키마와 클러스터의 뷰가 완전히 일치한다고 가정한다.
  - 이 둘의 일관성을 강제하지 않고 가정에 의존하면 심각한 문제가 생길 수 있다.
- ex) 아파치 카산드라
  - 스키마 변경 사항이 각 서버로 다른 시점에 전파되는 문제로 인한 버그 발견된 적 있음.
  - 서버가 서로 다른 형식의 스키마를 인코딩 혹은 디코딩하면서 데이터베이스가 손상
- ex) 카산드라 `링 상태 불일치 divergent view of the ring`
  - 한 노드가 다른 노드에 특정 키에 대한 레코드가 있다고 가정하지만, 해당 노드의 클러스터 뷰가 다른 노드와 다른 경우 읽거나 새로 쓴 데이터가 잘못된 위치에 배치되거나 데이터는 존재하지만 빈 응답을 반환하는 버그.

## 로컬 실행과 원격 실행

- 원격 API 뒤에 복잡한 로직을 숨기는 것은 위험할 수 있다.
  - 익숙하지 않은 스토리지 엔진을 사용하더라도 로컬 데이터셋의 반복자가 내부적으로 어떤 방식으로 동작하는지 쉽게 추론할 수 있다.
  - 하지만 원격 노드의 데이터셋을 순회하는 작업은 방식이 완전히 다르다. -> 일관성과 전달 방식, 데이터 조정, 페이징, 병합, 동시 접근 등 여러 부분에 관한 이해 필요
- 로컬 실행과 원격 실행은 완전히 다르다는 사실을 명심.
- 원격 실행을 감추기 어려운 이유는 바로 레이턴시.
  - 로컬보다 비용이 몇 배 이상 높다.
  - 양방향 네트워크 전송과 직렬화/역직렬화 등의 여러 단계가 추가되기 때문이다.
  - 원격 실행과 로컬 실행이 뒤섞이면 성능 저하와 부작용의 원인이 될 수 있다.

## 장애 처리

- 모든 노드가 정상적으로 작동한다고 가정하고 시스템 설계를 시작하는 것도 괜찮지만 항상 이렇게 가정하는 것은 위험하다.
  - 점검을 위해 `중단 graceful shutdown`되기도 하고 소프트웨어 문제, `메모리 부족 킬러 out-of-memory killer`, 런타임 버그, 하드웨어 문제 등으로 인해 노드에 장애가 발생하기도 한다.
  - 프로세스는 중단될 수 있다. 따라서 장애 상황에 대비하고 어떻게 대처할 수 있을지 고민해야 한다.
- 원격 서버가 응답하지 않는 정확한 이유를 항상 알 수 있는 것이 아니다.
  - 충돌, 네트워크 장애, 원격 프로세스 또는 링크의 속도 저하 등의 다양한 원인이 있을 수 있다.
  - 일부 분산 알고리즘은 `하트비트 프로토콜 heartbeat protocol`과 `장애 검출기 failure detector`를 사용해 어떤 노드가 살아 있고 접근 가능한지 추측한다.

## 네트워크 파션 부분 장애

- 2개 이상의 서버가 서로 통신할 수 없는 상황을 네트워크 파티션이 발생했다고 한다.
- 불안정한 네트워크(패킷 분실, 재전송, 예측할 수 없는 레이턴시 등)는 견디고 대처할 수 있지만, 네트워크 파티션은 훨씬 더 심각한 문제다.
  - 격리된 그룹이 각자 작업을 수행해 결과가 충돌할 수 있기 때문이다.
  - 비대칭 네트워크 링크가 발생할 수도 있다. -> 메시지가 한 프로세스에서 다른 프로세스로 성공적으로 전달되지만 반대 방향은 실패하는 경우
- 장애 감지는 쉽지 않다. -> 모든 부분에서 동일한 형태로 발생하지 않는다.
  - 가용성이 높은 시스템을 설계할 때는 항상 여러 특수 상황을 고려해야 한다.
  - 데이터를 성공적으로 복제했지만 확인 응답을 받지 못했다면 재시도할 것인가?
  - 확인 응답을 보낸 노드의 데이터는 읽기를 허용할 것인가?
- 장애에 대처하는 가장 이상적인 방법 = 테스트
  - 파티션 생성, 비트 손상 시뮬레이션, 레이턴시 증가, 클럭 불일치 유발, 상대적 처리 속도 증가 등을 설정할 수 있는 `테스트 하네스 test harness`를 준비해야 한다.
  - 상용 분산 시스템은 매우 적대적이고 불친절하며 창조적일 수 있다. 따라서 테스트는 가능한 한 많은 시나리오를 포함해야 한다.
- 분산 시스템 설계 시 내결함성, 회복력, 장애 시나리오 그리고 여러 특수 상황을 모두 신중하게 고려해야 한다.
  - 일반적으로 클러스터에는 항상 문제가 발생하기 마련이다.

## `계단식 장애 cascading failures`

- 장애는 분리가 불가능할 수 있다.
  - 특정 프로세스의 사용량이 급증하면 결국 클러스터 전체의 사용량이 증가해 다른 노드에도 장애가 발생할 확률이 높아진다.
  - 계단식 장애는 시스템의 한 부분에서 다른 부분으로 전파돼 오류의 범위를 확장한다.

> 시스템 내에 장애가 전파되는 것을 방지하고 장애 상황에 적절하게 대응하기 위해 `Circuit Breaker`를 사용하기도 한다.

- 특정 서버와의 연결이 끊어지거나 서버가 응답하지 않는 경우 클라이언트는 계속해서 재연결을 시도한다.
  - 하지만 과부하가 걸린 서버는 새로운 접속 요청을 처리하는데 바쁘기 때문에 지속적인 재연결 시도는 상황을 악화시킨다.
  - 이와 같은 상황을 방지하기 위해 `백오프 backoff` 전략을 사용한다. -> 재시도를 스케줄링하고 요청 사이의 시간을 늘려 증폭 문제 해결
- 하지만 여러 클라이언트가 동일한 백오프 전략을 사용할 경우 상당한 부하가 발생할 수 있다.
  - 여러 클라이언트가 백오프 기간이 지나고 동시에 재시도하는 상황을 방지하기 위해 `지터 Jitter`를 사용한다.
  - 백오프 기간에 임의의 짧은 시간을 추가해 여러 클라이언트가 동시에 재시도하는 확률을 줄인다.
- 하드웨어 장애와 비트 손상, 소프트웨어 에러로 인해 손상된 데이터 전송 및 전파 -> 정상적인 레코드 덮어씀
  - 이와 같은 문제는 `체크섬 checksum`과 유효성 검증을 통해 노드 사이에 교환되는 데이터의 무결성을 확인해야 한다.
- 부하와 `핫스팟 hotspot`은 작업을 미리 계획하고 조정함으로써 방지할 수 있다.
  - 각 노드가 독립적으로 작업을 수행하지 않고 코디네이터가 가용 리소스를 기반으로 실행 계획을 준비하고 과거 실행 데이터 기반으로 부하를 예측해야 한다.
- 장애 전파는 미리 차단하자!
  - Circuit Breaker, 백오프 전략, 유효성 검증 및 조정 메커니즘을 구현해야 한다.
  - 분리된 작은 문제를 해결하는 것이 대규모 장애를 복구하는 것보다 훨씬 더 간단하다.

